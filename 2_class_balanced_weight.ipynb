{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_class_balanced_weight.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHXh0LFAyyZ1",
        "colab_type": "code",
        "outputId": "072d90f3-9fa6-4e3b-c017-5b44a4a052b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from keras.models import load_model\n",
        "from __future__ import print_function\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import applications\n",
        "import cv2 \n",
        "from os import listdir\n",
        "import numpy as np\n",
        "import matplotlib. pyplot as plt\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, AveragePooling2D,GlobalAveragePooling2D,Activation,BatchNormalization,Dropout,Concatenate\n",
        "from keras.models import Model\n",
        "from keras.applications import DenseNet121\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.optimizers import Adam, Adamax\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras import optimizers\n",
        "#Augmentation\n",
        "from numpy import expand_dims\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.utils import class_weight\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, ReduceLROnPlateau, TensorBoard, EarlyStopping\n",
        "from sklearn.model_selection import KFold,StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "import urllib,math"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHsMVvn6NTpr",
        "colab_type": "code",
        "outputId": "c5559d05-927d-4288-974a-56da008c9fcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhK3ZfW4Fi7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augment(images,num):\n",
        "  aug = []\n",
        "  datagens = []\n",
        "  datagens.append(ImageDataGenerator(width_shift_range=0.15))\n",
        "  datagens.append(ImageDataGenerator(height_shift_range=0.15))\n",
        "  datagens.append(ImageDataGenerator(horizontal_flip=True))\n",
        "  datagens.append(ImageDataGenerator(rotation_range=45))\n",
        "  datagens.append(ImageDataGenerator(brightness_range=[0.6,1]))\n",
        "  datagens.append(ImageDataGenerator(zoom_range=0.15))\n",
        "  for data in images:\n",
        "    samples = expand_dims(data, 0)\n",
        "    for datagen in datagens:\n",
        "      it = datagen.flow(samples, batch_size=1)\n",
        "      for i in range(num):\n",
        "        batch = it.next()\n",
        "        image = batch[0].astype('uint8')\n",
        "        aug.append(image)\n",
        "  return aug"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdpJlSCqN_OY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train=np.load('/content/drive/My Drive/Corona_Image/Pavel/Data/v3/x_train.npy')\n",
        "y_train1=np.load('/content/drive/My Drive/Corona_Image/Pavel/Data/v3/y_train.npy')\n",
        "x_test=np.load('/content/drive/My Drive/Corona_Image/Pavel/Data/v3/x_test.npy')\n",
        "y_test1=np.load('/content/drive/My Drive/Corona_Image/Pavel/Data/v3/y_test.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lm97au1pDbPx",
        "colab_type": "code",
        "outputId": "63899a24-d72a-40db-c03f-0a40003d9160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(np.unique(y_train1,return_counts=True))\n",
        "print(np.unique(y_test1,return_counts=True))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([0, 1, 2], dtype=int32), array([7966, 5451,  207]))\n",
            "(array([0, 1, 2], dtype=int32), array([885, 594,  31]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t42ZXz1QC64w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_two_class(arr):\n",
        "  arr[arr == 1] = 0\n",
        "  arr[arr == 2] = 1\n",
        "  return arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG_VDtiFER2B",
        "colab_type": "code",
        "outputId": "5c80ce05-c9d3-406c-e713-a87c982a281d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "y_train=make_two_class(y_train1)\n",
        "y_test=make_two_class(y_test1)\n",
        "print(np.unique(y_train1,return_counts=True))\n",
        "print(np.unique(y_test1,return_counts=True))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([0, 1], dtype=int32), array([13417,   207]))\n",
            "(array([0, 1], dtype=int32), array([1479,   31]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAMLgHPjRIWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_cat = np_utils.to_categorical(y_train, 2)\n",
        "train_data, val_data, train_label, val_label = train_test_split(x_train, y_train_cat, test_size=0.1, random_state=42, stratify=y_train_cat)\n",
        "train_label = np.argmax(train_label,axis=1)\n",
        "corona = train_data[train_label==1]\n",
        "aug = np.array(augment(corona,9))\n",
        "label = np.empty(aug.shape[0],dtype='int32')\n",
        "label.fill(1)\n",
        "train_data = np.concatenate((train_data, aug), axis=0)\n",
        "train_label = np.concatenate((train_label, label), axis=0)\n",
        "train_data,train_label=shuffle(train_data,train_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVpLzgPjKtbD",
        "colab_type": "code",
        "outputId": "d5902d1d-f9c2-48e0-d235-9626d4639989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(np.unique(train_label,return_counts=True))\n",
        "train_label = np_utils.to_categorical(train_label, 2)\n",
        "print(train_data.shape,train_label.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([0, 1]), array([12075, 10230]))\n",
            "(22305, 224, 224, 3) (22305, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQdGnLqtE16C",
        "colab_type": "code",
        "outputId": "911e2906-e36a-4134-94db-de77e551b9f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "val_label = np.argmax(val_label,axis=1)\n",
        "corona = val_data[val_label==1]\n",
        "aug = np.array(augment(corona,9))\n",
        "label = np.empty(aug.shape[0],dtype='int32')\n",
        "label.fill(1)\n",
        "val_data = np.concatenate((val_data, aug), axis=0)\n",
        "val_label = np.concatenate((val_label, label), axis=0)\n",
        "print(np.unique(val_label,return_counts=True))\n",
        "val_label = np_utils.to_categorical(val_label, 2)\n",
        "val_data,val_label=shuffle(val_data,val_label)\n",
        "print(val_data.shape,val_label.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([0, 1]), array([1342, 1155]))\n",
            "(2497, 224, 224, 3) (2497, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFAWWCXd6Po5",
        "colab_type": "code",
        "outputId": "7765e50e-1af0-4800-cba0-eaeaea69e98c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        }
      },
      "source": [
        "densenet = DenseNet121(weights='/content/drive/My Drive/Corona_Image/chexnet_weights.h5',\n",
        "        # weights = None ,\n",
        "        include_top=True,\n",
        "        input_shape=(224,224,3),classes=14\n",
        "      )\n",
        "      \n",
        "m = densenet.layers[-2].output\n",
        "predictions = Dense(2, activation='softmax')(m)\n",
        "model = Model(inputs=densenet.inputs, outputs=predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAmzfaZU9Dbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def binary_accuracy(y_true, y_pred):\n",
        "    return K.mean(K.equal(y_true, K.round(y_pred)))\n",
        "\n",
        "\n",
        "def categorical_accuracy(y_true, y_pred):\n",
        "    return K.mean(K.equal(K.argmax(y_true, axis=-1),\n",
        "                          K.argmax(y_pred, axis=-1)))\n",
        "\n",
        "\n",
        "def sparse_categorical_accuracy(y_true, y_pred):\n",
        "    return K.mean(K.equal(K.max(y_true, axis=-1),\n",
        "                          K.cast(K.argmax(y_pred, axis=-1), K.floatx())))\n",
        "\n",
        "\n",
        "def top_k_categorical_accuracy(y_true, y_pred, k=5):\n",
        "    return K.mean(K.in_top_k(y_pred, K.argmax(y_true, axis=-1), k))\n",
        "\n",
        "\n",
        "def mean_squared_error(y_true, y_pred):\n",
        "    return K.mean(K.square(y_pred - y_true))\n",
        "\n",
        "\n",
        "def mean_absolute_error(y_true, y_pred):\n",
        "    return K.mean(K.abs(y_pred - y_true))\n",
        "\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    diff = K.abs((y_true - y_pred) / K.clip(K.abs(y_true),\n",
        "                                            K.epsilon(),\n",
        "                                            None))\n",
        "    return 100. * K.mean(diff)\n",
        "\n",
        "\n",
        "def mean_squared_logarithmic_error(y_true, y_pred):\n",
        "    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n",
        "    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n",
        "    return K.mean(K.square(first_log - second_log))\n",
        "\n",
        "\n",
        "def hinge(y_true, y_pred):\n",
        "    return K.mean(K.maximum(1. - y_true * y_pred, 0.))\n",
        "\n",
        "\n",
        "def squared_hinge(y_true, y_pred):\n",
        "    return K.mean(K.square(K.maximum(1. - y_true * y_pred, 0.)))\n",
        "\n",
        "\n",
        "def categorical_crossentropy(y_true, y_pred):\n",
        "    return K.mean(K.categorical_crossentropy(y_pred, y_true))\n",
        "\n",
        "\n",
        "def sparse_categorical_crossentropy(y_true, y_pred):\n",
        "    return K.mean(K.sparse_categorical_crossentropy(y_pred, y_true))\n",
        "\n",
        "\n",
        "def binary_crossentropy(y_true, y_pred):\n",
        "    return K.mean(K.binary_crossentropy(y_pred, y_true))\n",
        "\n",
        "\n",
        "def kullback_leibler_divergence(y_true, y_pred):\n",
        "    y_true = K.clip(y_true, K.epsilon(), 1)\n",
        "    y_pred = K.clip(y_pred, K.epsilon(), 1)\n",
        "    return K.mean(K.sum(y_true * K.log(y_true / y_pred), axis=-1))\n",
        "\n",
        "\n",
        "def poisson(y_true, y_pred):\n",
        "    return K.mean(y_pred - y_true * K.log(y_pred + K.epsilon()))\n",
        "\n",
        "\n",
        "def cosine_proximity(y_true, y_pred):\n",
        "    y_true = K.l2_normalize(y_true, axis=-1)\n",
        "    y_pred = K.l2_normalize(y_pred, axis=-1)\n",
        "    return -K.mean(y_true * y_pred)\n",
        "\n",
        "\n",
        "def matthews_correlation(y_true, y_pred):\n",
        "    \"\"\"Matthews correlation metric.\n",
        "    It is only computed as a batch-wise average, not globally.\n",
        "    Computes the Matthews correlation coefficient measure for quality\n",
        "    of binary classification problems.\n",
        "    \"\"\"\n",
        "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
        "    y_pred_neg = 1 - y_pred_pos\n",
        "\n",
        "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
        "    y_neg = 1 - y_pos\n",
        "\n",
        "    tp = K.sum(y_pos * y_pred_pos)\n",
        "    tn = K.sum(y_neg * y_pred_neg)\n",
        "\n",
        "    fp = K.sum(y_neg * y_pred_pos)\n",
        "    fn = K.sum(y_pos * y_pred_neg)\n",
        "\n",
        "    numerator = (tp * tn - fp * fn)\n",
        "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
        "\n",
        "    return numerator / (denominator + K.epsilon())\n",
        "\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    \"\"\"Precision metric.\n",
        "    Only computes a batch-wise average of precision.\n",
        "    Computes the precision, a metric for multi-label classification of\n",
        "    how many selected items are relevant.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    \"\"\"Recall metric.\n",
        "    Only computes a batch-wise average of recall.\n",
        "    Computes the recall, a metric for multi-label classification of\n",
        "    how many relevant items are selected.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def fbeta_score(y_true, y_pred, beta=1):\n",
        "    \"\"\"Computes the F score.\n",
        "    The F score is the weighted harmonic mean of precision and recall.\n",
        "    Here it is only computed as a batch-wise average, not globally.\n",
        "    This is useful for multi-label classification, where input samples can be\n",
        "    classified as sets of labels. By only using accuracy (precision) a model\n",
        "    would achieve a perfect score by simply assigning every class to every\n",
        "    input. In order to avoid this, a metric should penalize incorrect class\n",
        "    assignments as well (recall). The F-beta score (ranged from 0.0 to 1.0)\n",
        "    computes this, as a weighted mean of the proportion of correct class\n",
        "    assignments vs. the proportion of incorrect class assignments.\n",
        "    With beta = 1, this is equivalent to a F-measure. With beta < 1, assigning\n",
        "    correct classes becomes more important, and with beta > 1 the metric is\n",
        "    instead weighted towards penalizing incorrect class assignments.\n",
        "    \"\"\"\n",
        "    if beta < 0:\n",
        "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
        "\n",
        "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
        "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
        "        return 0\n",
        "\n",
        "    p = precision(y_true, y_pred)\n",
        "    r = recall(y_true, y_pred)\n",
        "    bb = beta ** 2\n",
        "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
        "    return fbeta_score\n",
        "\n",
        "\n",
        "def fmeasure(y_true, y_pred):\n",
        "    \"\"\"Computes the f-measure, the harmonic mean of precision and recall.\n",
        "    Here it is only computed as a batch-wise average, not globally.\n",
        "    \"\"\"\n",
        "    return fbeta_score(y_true, y_pred, beta=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0xVxW7Y6Smj",
        "colab_type": "code",
        "outputId": "ea749f24-e9c9-4895-802f-bd9305ec9fca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        }
      },
      "source": [
        "adam = Adamax(learning_rate=0.00001, beta_1=0.9, beta_2=0.999)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=adam,metrics=['accuracy', precision, recall, fbeta_score])\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
        "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
        "#class_weights = {0: 3, 1: 7}\n",
        "history = model.fit(train_data, train_label, batch_size=16,\n",
        "                         epochs=100,verbose=1, validation_data=(val_data,val_label), shuffle=True, class_weight=class_weights,\n",
        "                           callbacks=[reduce_lr, es])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 22305 samples, validate on 2497 samples\n",
            "Epoch 1/100\n",
            "22305/22305 [==============================] - 741s 33ms/step - loss: 0.6395 - accuracy: 0.6877 - precision: 0.6879 - recall: 0.6879 - fbeta_score: 0.6879 - val_loss: 0.5941 - val_accuracy: 0.7869 - val_precision: 0.7882 - val_recall: 0.7882 - val_fbeta_score: 0.7882\n",
            "Epoch 2/100\n",
            "22305/22305 [==============================] - 707s 32ms/step - loss: 0.5763 - accuracy: 0.7852 - precision: 0.7847 - recall: 0.7847 - fbeta_score: 0.7847 - val_loss: 0.5265 - val_accuracy: 0.8150 - val_precision: 0.8161 - val_recall: 0.8161 - val_fbeta_score: 0.8161\n",
            "Epoch 3/100\n",
            "22305/22305 [==============================] - 709s 32ms/step - loss: 0.5123 - accuracy: 0.8214 - precision: 0.8209 - recall: 0.8209 - fbeta_score: 0.8209 - val_loss: 0.4584 - val_accuracy: 0.8390 - val_precision: 0.8400 - val_recall: 0.8400 - val_fbeta_score: 0.8400\n",
            "Epoch 4/100\n",
            "22305/22305 [==============================] - 709s 32ms/step - loss: 0.4391 - accuracy: 0.8564 - precision: 0.8565 - recall: 0.8565 - fbeta_score: 0.8565 - val_loss: 0.3837 - val_accuracy: 0.8759 - val_precision: 0.8766 - val_recall: 0.8766 - val_fbeta_score: 0.8766\n",
            "Epoch 5/100\n",
            "22305/22305 [==============================] - 707s 32ms/step - loss: 0.3569 - accuracy: 0.8843 - precision: 0.8837 - recall: 0.8837 - fbeta_score: 0.8837 - val_loss: 0.3042 - val_accuracy: 0.8963 - val_precision: 0.8969 - val_recall: 0.8969 - val_fbeta_score: 0.8969\n",
            "Epoch 6/100\n",
            "22305/22305 [==============================] - 706s 32ms/step - loss: 0.2874 - accuracy: 0.9027 - precision: 0.9028 - recall: 0.9028 - fbeta_score: 0.9028 - val_loss: 0.2539 - val_accuracy: 0.9059 - val_precision: 0.9064 - val_recall: 0.9064 - val_fbeta_score: 0.9064\n",
            "Epoch 7/100\n",
            "22305/22305 [==============================] - 704s 32ms/step - loss: 0.2397 - accuracy: 0.9140 - precision: 0.9134 - recall: 0.9134 - fbeta_score: 0.9134 - val_loss: 0.2302 - val_accuracy: 0.9079 - val_precision: 0.9084 - val_recall: 0.9084 - val_fbeta_score: 0.9084\n",
            "Epoch 8/100\n",
            "22305/22305 [==============================] - 710s 32ms/step - loss: 0.2126 - accuracy: 0.9198 - precision: 0.9192 - recall: 0.9192 - fbeta_score: 0.9192 - val_loss: 0.2097 - val_accuracy: 0.9155 - val_precision: 0.9160 - val_recall: 0.9160 - val_fbeta_score: 0.9160\n",
            "Epoch 9/100\n",
            "22305/22305 [==============================] - 708s 32ms/step - loss: 0.1915 - accuracy: 0.9280 - precision: 0.9274 - recall: 0.9274 - fbeta_score: 0.9274 - val_loss: 0.1971 - val_accuracy: 0.9183 - val_precision: 0.9188 - val_recall: 0.9188 - val_fbeta_score: 0.9188\n",
            "Epoch 10/100\n",
            "22305/22305 [==============================] - 708s 32ms/step - loss: 0.1729 - accuracy: 0.9369 - precision: 0.9369 - recall: 0.9369 - fbeta_score: 0.9369 - val_loss: 0.1867 - val_accuracy: 0.9207 - val_precision: 0.9212 - val_recall: 0.9212 - val_fbeta_score: 0.9212\n",
            "Epoch 11/100\n",
            "22305/22305 [==============================] - 709s 32ms/step - loss: 0.1579 - accuracy: 0.9424 - precision: 0.9424 - recall: 0.9424 - fbeta_score: 0.9424 - val_loss: 0.1881 - val_accuracy: 0.9151 - val_precision: 0.9156 - val_recall: 0.9156 - val_fbeta_score: 0.9156\n",
            "Epoch 12/100\n",
            "22305/22305 [==============================] - 710s 32ms/step - loss: 0.1478 - accuracy: 0.9463 - precision: 0.9463 - recall: 0.9463 - fbeta_score: 0.9463 - val_loss: 0.1824 - val_accuracy: 0.9159 - val_precision: 0.9164 - val_recall: 0.9164 - val_fbeta_score: 0.9164\n",
            "Epoch 13/100\n",
            "22305/22305 [==============================] - 710s 32ms/step - loss: 0.1378 - accuracy: 0.9487 - precision: 0.9481 - recall: 0.9481 - fbeta_score: 0.9481 - val_loss: 0.1801 - val_accuracy: 0.9179 - val_precision: 0.9184 - val_recall: 0.9184 - val_fbeta_score: 0.9184\n",
            "Epoch 14/100\n",
            "22305/22305 [==============================] - 710s 32ms/step - loss: 0.1253 - accuracy: 0.9560 - precision: 0.9560 - recall: 0.9560 - fbeta_score: 0.9560 - val_loss: 0.1766 - val_accuracy: 0.9211 - val_precision: 0.9216 - val_recall: 0.9216 - val_fbeta_score: 0.9216\n",
            "Epoch 15/100\n",
            "22305/22305 [==============================] - 709s 32ms/step - loss: 0.1196 - accuracy: 0.9560 - precision: 0.9553 - recall: 0.9553 - fbeta_score: 0.9553 - val_loss: 0.1764 - val_accuracy: 0.9215 - val_precision: 0.9220 - val_recall: 0.9220 - val_fbeta_score: 0.9220\n",
            "Epoch 16/100\n",
            "22305/22305 [==============================] - 708s 32ms/step - loss: 0.1148 - accuracy: 0.9582 - precision: 0.9582 - recall: 0.9582 - fbeta_score: 0.9582 - val_loss: 0.1764 - val_accuracy: 0.9211 - val_precision: 0.9216 - val_recall: 0.9216 - val_fbeta_score: 0.9216\n",
            "Epoch 17/100\n",
            "22305/22305 [==============================] - 705s 32ms/step - loss: 0.1036 - accuracy: 0.9635 - precision: 0.9635 - recall: 0.9635 - fbeta_score: 0.9635 - val_loss: 0.1738 - val_accuracy: 0.9231 - val_precision: 0.9236 - val_recall: 0.9236 - val_fbeta_score: 0.9236\n",
            "Epoch 18/100\n",
            "22305/22305 [==============================] - 705s 32ms/step - loss: 0.1003 - accuracy: 0.9635 - precision: 0.9635 - recall: 0.9635 - fbeta_score: 0.9635 - val_loss: 0.1801 - val_accuracy: 0.9203 - val_precision: 0.9208 - val_recall: 0.9208 - val_fbeta_score: 0.9208\n",
            "Epoch 19/100\n",
            "22305/22305 [==============================] - 707s 32ms/step - loss: 0.0969 - accuracy: 0.9663 - precision: 0.9664 - recall: 0.9664 - fbeta_score: 0.9664 - val_loss: 0.1746 - val_accuracy: 0.9255 - val_precision: 0.9260 - val_recall: 0.9260 - val_fbeta_score: 0.9260\n",
            "Epoch 20/100\n",
            "22305/22305 [==============================] - 706s 32ms/step - loss: 0.0940 - accuracy: 0.9675 - precision: 0.9668 - recall: 0.9668 - fbeta_score: 0.9668 - val_loss: 0.1765 - val_accuracy: 0.9243 - val_precision: 0.9248 - val_recall: 0.9248 - val_fbeta_score: 0.9248\n",
            "Epoch 21/100\n",
            "22305/22305 [==============================] - 703s 32ms/step - loss: 0.0893 - accuracy: 0.9680 - precision: 0.9673 - recall: 0.9673 - fbeta_score: 0.9673 - val_loss: 0.1803 - val_accuracy: 0.9231 - val_precision: 0.9236 - val_recall: 0.9236 - val_fbeta_score: 0.9236\n",
            "Epoch 22/100\n",
            " 9728/22305 [============>.................] - ETA: 6:28 - loss: 0.0853 - accuracy: 0.9698 - precision: 0.9698 - recall: 0.9698 - fbeta_score: 0.9698"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5ZAoeHs4QCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}